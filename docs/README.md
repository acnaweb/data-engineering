
# üìò Roadmap Completo: Engenharia de Dados com GCP

---

## üéØ Escala de Conhecimento por N√≠vel

| N√≠vel        | Descri√ß√£o Geral                                                                 |
|--------------|----------------------------------------------------------------------------------|
| **J√∫nior**   | Conhece os fundamentos, executa tarefas com supervis√£o, entende o b√°sico da nuvem e dados |
| **Pleno**    | Executa com autonomia, compreende arquitetura e boas pr√°ticas, contribui com solu√ß√µes |
| **S√™nior**   | Lidera iniciativas, prop√µe melhorias, domina arquitetura e pipelines fim a fim  |
| **Especialista** | Define padr√µes, mentora outros, projeta solu√ß√µes complexas, representa a √°rea em decis√µes t√©cnicas |

---

## üß≠ Roadmap de Estudo ‚Äì Engenharia de Dados com GCP

| Fase    | T√≥pico a Estudar                  | Exemplos                                           | Entreg√°veis                                                                 | Cronograma     |
|---------|----------------------------------|----------------------------------------------------|------------------------------------------------------------------------------|----------------|
| Fase 1  | Comandos b√°sicos de Linux        | ls, cd, grep, find, chmod, crontab                 | Scripts bash versionados                                                    | Semanas 1‚Äì4    |
| Fase 1  | Shell scripting                   | scripts para backup, parsing de logs              | Scripts de automa√ß√£o com shell                                              | Semanas 1‚Äì4    |
| Fase 1  | Fundamentos de Redes              | HTTP vs HTTPS, ping, traceroute, NAT              | Documenta√ß√£o de rede VPC simulada                                           | Semanas 1‚Äì4    |
| Fase 1  | Git b√°sico e avan√ßado             | git clone, merge, rebase, GitFlow                 | Reposit√≥rio Git com branches e PRs                                          | Semanas 1‚Äì4    |
| Fase 1  | Python b√°sico                     | fun√ß√µes, classes, m√≥dulos, pandas                 | Scripts ETL simples com pandas                                              | Semanas 1‚Äì4    |
| Fase 1  | SQL avan√ßado                      | JOINs, CTEs, √≠ndices, window functions            | Queries otimizadas e versionadas                                            | Semanas 1‚Äì4    |
| Fase 2  | Modelagem de dados OLTP e OLAP    | 3NF, Star Schema, Snowflake Schema                | Modelos conceituais no dbdiagram.io                                         | Semanas 5‚Äì10   |
| Fase 2  | BigQuery avan√ßado                 | partitioning, clustering, materialized views      | Tabelas otimizadas e consultas complexas                                    | Semanas 5‚Äì10   |
| Fase 2  | Cloud Storage e IAM               | cria√ß√£o de buckets, roles, uniform access         | Configura√ß√£o de buckets versionados                                         | Semanas 5‚Äì10   |
| Fase 2  | Dataflow / Apache Beam            | PCollection, ParDo, janela de tempo               | Pipeline simples com templates parametrizados                               | Semanas 5‚Äì10   |
| Fase 2  | Pub/Sub                           | pub/sub topics, dead-letter topics                | Configura√ß√£o de t√≥pico + subscri√ß√£o com DLQ                                 | Semanas 5‚Äì10   |
| Fase 2  | Apache Airflow (Composer)         | DAGs, Operators, XCom                             | DAG com m√∫ltiplas depend√™ncias e paralelismo                                | Semanas 5‚Äì10   |
| Fase 2  | Dataform / dbt                    | incremental models, testes de schema              | Tabelas incrementais com testes e documenta√ß√£o                              | Semanas 5‚Äì10   |
| Fase 3  | Arquitetura GCP                   | VPC, subnets, NAT gateway, Cloud Run              | Diagrama C4 e plano de arquitetura GCP                                      | Semanas 11‚Äì16  |
| Fase 3  | Design Patterns para dados        | pipeline, event-driven, CQRS                      | Documenta√ß√£o com padr√µes aplicados                                          | Semanas 11‚Äì16  |
| Fase 3  | CI/CD e DataOps                   | GitHub Actions, Terraform tfvars                  | Pipelines com m√∫ltiplos ambientes e tfvars                                  | Semanas 11‚Äì16  |
| Fase 3  | Testes em pipelines de dados      | Great Expectations, Pytest                        | Testes automatizados com assertions e CI                                    | Semanas 11‚Äì16  |
| Fase 3  | Observabilidade e qualidade       | Stackdriver, Prometheus, Data Catalog             | Painel de m√©tricas e alertas configurados                                   | Semanas 11‚Äì16  |
| Fase 3  | Governan√ßa e Seguran√ßa            | DLP, pol√≠ticas de masking, RBAC                   | Policies, roles e criptografia de dados sens√≠veis                           | Semanas 11‚Äì16  |
| Fase 4  | ML com Vertex AI                  | Feature Store, treinamento e deploy de modelos    | Pipeline completo com treinamento e serving                                 | Semanas 17‚Äì24  |
| Fase 4  | Data Contracts                    | jsonschema, Pydantic, OpenAPI                     | YAMLs versionados e validados via CLI                                       | Semanas 17‚Äì24  |
| Fase 4  | Streaming com Kafka e Flink       | event time, watermarks                            | Pipeline com Flink integrado a Pub/Sub                                      | Semanas 17‚Äì24  |
| Fase 4  | Data Mesh                         | dom√≠nios, produtos de dados                       | PoC com 2 dom√≠nios e contratos independentes                                | Semanas 17‚Äì24  |
| Fase 4  | Projeto Final                     | pipeline batch+stream+ML                          | Projeto p√∫blico com documenta√ß√£o e CI/CD                                    | Semanas 17‚Äì24  |

---

## üèóÔ∏è Arquiteturas de Refer√™ncia

| Arquitetura | Defini√ß√£o | Quando Usar | Aplica√ß√£o na GCP |
|-------------|-----------|-------------|------------------|
| **Lambda**  | Combina batch e streaming com camadas distintas | Sistemas legados que precisam evoluir para streaming | Pub/Sub, Dataflow, BigQuery, Composer |
| **Kappa**   | Trata todo o fluxo como streaming               | Sistemas orientados a eventos em tempo real           | Pub/Sub, Dataflow (stream), BigQuery, Looker |
| **Medallion** | Organiza dados em Bronze, Silver, Gold         | Governan√ßa e rastreabilidade no Data Lake             | GCS, Dataflow, BigQuery, Dataform, Data Catalog |

---

## üí° Desafios por Arquitetura

### üîπ Lambda Architecture ‚Äì Detec√ß√£o de Fraude Banc√°ria
- **Problema**: Detectar transa√ß√µes suspeitas em tempo real e manter dados hist√≥ricos.
- **Objetivo**: Pipeline h√≠brido com batch e streaming.
- **Entradas**: Pub/Sub (real-time) + CSVs di√°rios no Cloud Storage.
- **Componentes GCP**: Pub/Sub, Dataflow, BigQuery, Composer.
- **Entreg√°veis**:
  - DAG Composer com ingest√£o h√≠brida
  - Pipeline com Dataflow (batch e stream)
  - Views anal√≠ticas cruzando dados

### üîπ Kappa Architecture ‚Äì Telemetria IoT em Tempo Real
- **Problema**: Detectar anomalias em sensores industriais via stream.
- **Objetivo**: Pipeline 100% streaming com alerta e painel.
- **Entradas**: Eventos JSON via Pub/Sub.
- **Componentes GCP**: Pub/Sub, Dataflow, BigQuery, Looker, Cloud Functions.
- **Entreg√°veis**:
  - Pipeline com Watermarks
  - Alertas autom√°ticos
  - Dashboard anal√≠tico

### üîπ Medallion Architecture ‚Äì An√°lise de Vendas com Governan√ßa
- **Problema**: Integrar dados de ERP, e-commerce e CRM com governan√ßa.
- **Objetivo**: Implementar arquitetura Medallion com camadas bronze, silver e gold.
- **Entradas**: JSON e CSV no Cloud Storage.
- **Componentes GCP**: GCS, Dataflow, BigQuery, Dataform, Data Catalog.
- **Entreg√°veis**:
  - Buckets organizados por camada
  - Modelos incrementais e testes no Dataform
  - Metadados e lineage no Data Catalog

---

## üìä Matriz de Avalia√ß√£o por Tema e N√≠vel

| Tema                     | J√∫nior                                      | Pleno                                        | S√™nior                                       | Especialista                                           |
|--------------------------|---------------------------------------------|----------------------------------------------|----------------------------------------------|--------------------------------------------------------|
| Linux e Shell            | Usa comandos b√°sicos                        | Automatiza tarefas com shell                 | Scripts para deploy/ETL                      | Otimiza ambientes e define padr√µes                     |
| Redes                   | Entende HTTP/DNS                            | Soluciona problemas b√°sicos                  | Desenha redes para pipelines                 | Planeja VPCs, NAT, firewalls e seguran√ßa               |
| Git/GitHub              | Clone e commit                              | Branching, PRs, GitFlow                      | Estrat√©gias de versionamento                 | Integra√ß√£o com CI/CD                                   |
| Python                  | Scripts simples com pandas                  | Tipagem, testes, estrutura√ß√£o                | Bibliotecas reutiliz√°veis                    | SDKs, APIs, automa√ß√£o com GCP                          |
| SQL                     | SELECT, JOIN                                | CTEs, views, tuning                          | Modelagem dimensional                        | Arquitetura do warehouse                               |
| BigQuery                | Queries b√°sicas                             | Parti√ß√µes, clustering                        | Monitoramento e automa√ß√£o                    | Arquitetura anal√≠tica e governan√ßa de custos           |
| Dataflow / Beam         | Pipeline simples                            | Windowing, transforms                        | Pipelines parametrizados                     | Arquitetura tempo real e otimiza√ß√£o                    |
| Pub/Sub                 | Publica e consome mensagens                 | DLQ, ordering                                | Orquestra eventos                            | Alta performance com eventos                           |
| Composer / Airflow      | DAGs simples                                | XComs, depend√™ncias                          | Execu√ß√£o paralela                            | Arquitetura de orquestra√ß√£o                            |
| Dataform / dbt          | SQL simples                                 | Incremental, testes                          | CI/CD e ambientes                            | Padr√µes e modelo sem√¢ntico                             |
| Testes de Dados         | Valida√ß√µes manuais                          | Great Expectations                           | Testes automatizados                         | Estrat√©gia organizacional de qualidade                 |
| CI/CD e Terraform       | Entende pipeline b√°sico                     | Terraform e revis√£o                          | Infraestrutura modular                       | GitOps com CLI customizado                             |
| Observabilidade         | Logs simples                                | Dashboards e alertas                         | Tracing e SLA de dados                        | Padr√µes operacionais completos                         |
| Seguran√ßa e Governan√ßa  | Roles b√°sicos                               | RBAC, masking                                | Compliance                                   | Pol√≠ticas automatizadas e auditoria                    |
| ML e Vertex AI          | Treinamento b√°sico                          | Pipelines com deploy                         | MLOps com dados reais                         | M√©tricas, serving e automa√ß√£o                          |
| Data Contracts / Mesh   | Consome schema                              | Valida schema                                | Automatiza contratos                         | Arquitetura federada                                   |

---

## üß© Plano de Desenvolvimento Individual (PDI)

| N√≠vel        | Crit√©rio                    | Sugest√µes de Desenvolvimento |
|--------------|-----------------------------|-------------------------------|
| J√∫nior       | Nota m√©dia entre 0.0 e 1.4  | Cursos b√°sicos, supervis√£o pr√≥xima, foco em fundamentos |
| Pleno        | Nota m√©dia entre 1.5 e 2.4  | Projetos aut√¥nomos, testes, versionamento |
| S√™nior       | Nota m√©dia entre 2.5 e 2.9  | Lideran√ßa t√©cnica, CI/CD, monitoramento, mentoring |
| Especialista | Nota m√©dia entre 3.0 e 3.5  | Padr√µes t√©cnicos, inova√ß√£o, estrat√©gia e governan√ßa |

---

## üìå Plano de A√ß√£o Individual

| Nome   | Tema com Gap | Nota Atual | Meta | A√ß√µes Recomendadas                                                        | Prazo   | Respons√°vel         | Observa√ß√µes             |
|--------|--------------|------------|------|---------------------------------------------------------------------------|---------|----------------------|--------------------------|
| Ana    | Dataflow     | 1          | 2    | Estudar curso GCP Dataflow, criar pipeline com template                  | 30 dias | Ana + Mentor T√©cnico |                          |
| Carlos | ML           | 1          | 2    | Laborat√≥rio Vertex AI com Feature Store                                  | 45 dias | Carlos               |                          |
| Ana    | Airflow      | 1          | 2    | Criar DAG com m√∫ltiplas tarefas, XCom e depend√™ncias                     | 30 dias | Ana                  | Revisar com Tech Lead    |
| Jo√£o   | Data Mesh    | 2          | 3    | Ler material ThoughtWorks, simular dom√≠nio                               | 60 dias | Jo√£o                 | Apresentar em tech talk  |